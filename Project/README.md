# Log Classification Project

This project implements a hybrid log classification system, combining three complementary approaches to handle varying levels of complexity in log patterns. The classification methods ensure flexibility and effectiveness in processing predictable, complex, and poorly-labeled data patterns.

The project is designed to classify system logs (e.g., HTTP logs, user actions, and system notifications) using both regular expressions and machine learning techniques. The goal is to accurately categorize log messages into predefined categories such as System Notifications, HTTP Status, or User Actions.

---
**Classification Approaches**

Regular Expression (Regex):

Handles the most simplified and predictable patterns.
Useful for patterns that are easily captured using predefined rules.

**Sentence Transformer + Logistic Regression:**

Manages complex patterns when there is sufficient training data.
Utilizes embeddings generated by Sentence Transformers and applies Logistic Regression as the classification layer.

**LLM (Large Language Models):**

Used for handling complex patterns when sufficient labeled training data is not available.
Provides a fallback or complementary approach to the other methods.
---
![architecture](resources/arch.png)
## Requirements

To run this project, ensure you have Python 3.13.0 installed along with the following libraries:

- pandas
- scikit-learn
- sentence-transformers
- joblib
- numpy

---

## Installation

1. Clone this repository to your local machine:

   ```bash
   git clone https://github.com/fyraas93/classification-logs.git
   cd classification-logs
   ```

2. Install the required libraries:

   ```bash
   pip install -r requirements.txt
   ```

   Or install them individually:
   ```bash
   pip install pandas scikit-learn sentence-transformers joblib numpy
   ```

3. Prepare your dataset:

   - Place your log file (e.g., `test.csv`) in the `resources/` directory.
   - Ensure it contains at least the following columns:
     - `log_message`: The log messages to process.
     - `source`: (Optional) The source of logs, if available.

---

## Usage

### 1. Regex-Based Classification
To classify logs using regular expressions only, use the provided `classify_with_regex` function. Modify the predefined patterns in `classify.py` as needed.

### 2. Machine Learning Classification
For advanced classification, a combination of sentence embeddings and Logistic Regression is used:
1. **Training the Model:**
   - Train the model using the `train.py` script with your dataset:
     ```bash
     python train.py
     ```

2. **Classify New Logs:**
   - Classify log messages in a new dataset using:
     ```bash
     python classify.py
     ```

   The classified logs will be saved to a CSV file to ensure usability.

### 3. Fine-Tuning
Modify `classify_with_regex()` or the model parameters as needed to improve accuracy on your specific dataset.

---

## File Structure

```plaintext
classification-logs/
│
├── classify.py        # Core script to classify log messages
├── processor_regex.py # Script to train the Logistic Regression model
├── processor_llm.py   # Script to train the llm model
├── processor_bert.py  # Script to train the bert model
├── resources/         # Folder for storing datasets ( output.csv,test.csv)
├── training/          # Folder for storing dataset and Jupyter Notebook
├── models/            # Folder for storing trained model (synthetic_logs.csv)
├── README.md          # Project documentation 
└── requirements.txt   # List of dependencies
```

---

## Example of Usage

Here's an example of how to use the project:

1. **Log File Input:**
Upload a CSV file containing logs to the FastAPI endpoint for classification. Ensure the file has the following columns:
*source
*log_message

   Example of a sample CSV file (`test.csv`):
   ```csv
   log_message,source
   "User User42 logged in.","LegacyCRM"
   "System reboot initiated by user admin.","SystemLogs"
   "HTTP/1.1 404 Not Found","WebServerLogs"
   ```

2. **Running Classification:**
The output will be a CSV file with an additional column *target_label, which represents the classified label for each log entry.

   After running the classification, you will get an output CSV like:
   ```csv
   log_message,source,target_label
   "User User42 logged in.","LegacyCRM","User Action"
   "System reboot initiated by user admin.","SystemLogs","System Notification"
   "HTTP/1.1 404 Not Found","WebServerLogs","HTTP Status"
   ```

---

## Future Improvements

- Add support for custom log formats.
- Allow for user-defined categories during classification.

---

## Contributors

- **Hamrouni Firas** - [GitHub Profile](https://github.com/Fyraas93)


---

## License

This project is licensed under the MIT License. Feel free to use, modify, and distribute it as needed.